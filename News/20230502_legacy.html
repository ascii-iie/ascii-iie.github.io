<!DOCTYPE html>
<html>

<head>
    <title>News</title>
    <link rel="icon" type="image/x-icon" href="img/ASCII_1.ico" />
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/3.3.7/css/bootstrap.min.css">
    <link rel="stylesheet" href="../css_style.css">
    <script src="https://cdn.staticfile.org/jquery/2.1.1/jquery.min.js"></script>
    <script src="https://cdn.staticfile.org/twitter-bootstrap/3.3.7/js/bootstrap.min.js"></script>


</head>

<body>

    <div id="head">
        <iframe MARGINWIDTH=0 MARGINHEIGHT=0 HSPACE=0 VSPACE=0 FRAMEBORDER=0 SCROLLING=no src="../head.html"
            width="100%" height="auto">
        </iframe>
    </div>
    <div class="col-sm-12 column container-fluid">
        <div class="row">
            <div class="col-sm-2 col-md-offset-1 col-lg-offset-1 col-xl-offset-1" id="menulist">
                <a href="../News.html" class="list-group-item list-group-item-info active" id="textid">Acadamic News</a>
                <a href="../News.html" class="list-group-item list-group-item-info" id="textid">Daily News</a>

            </div>

            <div class="col-sm-8 column ">
                <ol class="breadcrumb">
                    <li class="active">Menu
                    </li>
                    <li class="active">Acadamic News
                    </li>
                </ol>


                <div class="col-sm-12 column">
                    <ul class="list-group list-group-flush">
                        <h3 align="center">【Breaking News】中科院信工所ASCII LAB的4篇工作被ACL 2023主会接收</h3>
                        <p align="center">
                            <font size="2" color="616460">发布时间：2023年5月2日</font>
                        </p>
                        <hr align size="3" color="#eee">
                        <p style="text-align: center"><img src="../img/acl-logo.png" width="630" height="150"
                                align="center"></p>
                        <p style="text-indent:2em;">
                            <font size="3">国际计算语言学年会（Annual Meeting of the Association for Computational
                                Linguistics，ACL）是自然语言处理领域国际顶级学术会议，并在CCF分类中被评为A类会议，今年是第61届会议，将于7月9日-14日在加拿大多伦多召开。5月2日，ACL
                                2023结果公布，ASCII Lab组投稿4篇均被主会录用。</font>
                        </p>
                        <br>
                        <p style="text-align: center">
                            <font size="4">①</font>
                        </p>
                        <p style="text-indent:2em;">
                            <font size="3">题目：Divide, Conquer, and Combine: Mixture of Semantic-Independent Experts for
                                Zero-Shot Dialogue State Tracking</font>
                        </p>
                        <p style="text-indent:2em;">
                            <font size="3">作者：王青悦，曹亚男，林政，王石，郭莉等</font>
                        </p>
                        <p style="text-indent:2em;">
                            <font size="3">
                                摘要：零样本的迁移学习旨在帮助任务型对话脱离标注数据适配多领域场景。已有工作大多从数据/模型层面提升通用性，忽略了样本的语义解耦，限制了零样本下对话状态追踪的表现。在本篇工作中，我们提出了简单高效的方案——“划分，解决和合并”，即明确地解耦可见数据的语义信息，利用混合专家机制提升健壮性。具体地，我们先独立地划分可见数据并训练多个语义独立的专家，随后通过我们设计的聚合机制来映射和推理未见样本。我们的方案在不添加任何额外知识的前提下，仅使用10M的可训练参数使模型在MultiWOZ
                                2.1数据集上提升至SOTA性能。</font>
                        </p>
                        <br>
                        <p style="text-align: center">
                            <font size="4">②</font>
                        </p>
                        <p style="text-indent:2em;">
                            <font size="3">题目：DiffusEmp: A Diffusion Model-Based Framework with Multi-Grained Control
                                for Empathetic Response Generation</font>
                        </p>
                        <p style="text-indent:2em;">
                            <font size="3">作者：毕冠群，曹亚男，谢玉强，林政等</font>
                        </p>
                        <p style="text-indent:2em;">
                            <font size="3">
                                摘要：在开放域对话中，共情是一个至关重要的因素，它自然地表达了一个人对他人的关心和理解。虽然已有方法对共情回复生成进行了研究，但这些方法生成的共情内容往往较为单调，即表达比较通用且枯燥。本文提出用显式控制来引导共情表达，并设计了一个基于条件扩散语言模型的框架DiffusEmp，以统一对话历史和面向属性的控制信号的使用。具体而言，本方法引入了交流机制、对话意图和语义框架作为多粒度信号，对共情回复实现粗粒度和细粒度的控制。此外，设计了一个特定的掩码策略来反映多粒度信号和回复词语之间的关系，并将其集成到扩散模型中，以影响生成过程。在基准数据集EmpatheticDialogue上的实验结果表明，我们的框架在不丢失上下文相关性的情况下，在可控性、信性和多样性方面优于竞争性基线。
                            </font>
                        </p>
                        <br>
                        <p style="text-align: center">
                            <font size="4">③</font>
                        </p>
                        <p style="text-indent:2em;">
                            <font size="3">题目：Towards Better Entity Linking with Multi-View enhanced Distillation</font>
                        </p>
                        <p style="text-indent:2em;">
                            <font size="3">作者：刘益，田原，练建勋，曹亚男，方芳等</font>
                        </p>
                        <p style="text-indent:2em;">
                            <font size="3">
                                摘要：稠密检索被广泛用于实体链接之中，以从大规模知识库中检索与提及（mentions）相关的实体（entities）。主流的稠密检索技术基于双编码器（dual-encoders）框架，分别将提及和实体的文本内容编码为单个向量（single-vector
                                representation），并通过点积等粗粒度的交互策略（coarse-grained
                                interaction）来建模两者之间的相关性，导致双编码器难以准确地对实体中与提及相关的部分（mention-relevant parts within
                                entities）进行建模，以匹配具有不同上下文的提及。针对此问题，本文提出了一种多视图增强的蒸馏（Multi-View enhanced Distillation,
                                MVD）框架，可以有效地将实体中提及相关部分的知识从具有深层次语境交互的交叉编码器（cross-encoders）转移到双编码器上，来学习多样化的，提及相关的实体表征（mention-relevant
                                entity representations）。每个实体被分成多个视图，以避免提及无关的信息（mention-irrelevant
                                information）被引入到实体表征中。我们进一步为该框架设计了交叉对齐和自对齐机制（cross-alignment and self-alignment
                                mechanisms），通过对齐交叉编码器与双编码器间提及相关的实体表征，来促进教师模型到学生模型的细粒度知识蒸馏。此外，我们保留了一个全局视图来对实体进行整体的建模，以避免全局的信息被分散到局部的视图中。实验证明，我们的方法在若干实体链接基准上取得了最佳的效果。
                            </font>
                        </p>
                        <br>
                        <p style="text-align: center">
                            <font size="4">④</font>
                        </p>
                        <p style="text-indent:2em;">
                            <font size="3">题目：Retrieve-and-Sample: Document-level Event Argument Extraction via Hybrid
                                Retrieval Augmentation</font>
                        </p>
                        <p style="text-indent:2em;">
                            <font size="3">作者：任昱冰，曹亚男，郭平，方芳，马伟，林政等</font>
                        </p>
                        <p style="text-indent:2em;">
                            <font size="3">
                                摘要：最近的研究表明，检索增强技术在许多生成式自然语言处理任务中的有效性已得到证明。这些技术能够以非参数化的方式显式地获取外部先验知识，并将检索到的参考样例视为增强文本生成的线索。检索增强技术通常使用基于相似性的检索策略，该策略基于一种简单的假设：检索的样例与原始输入越相似，其标签与输入标签越可能相似。然而，在篇章级事件论元抽取任务中，由于事件标签的复杂性和事件论元的稀疏性，这种假设并不总是成立。因此，本文提出了一个有趣的问题：如何为篇章级事件论元抽取任务设计检索策略？本文从输入分布和标签分布的视角探究了多种检索设置，并进一步提出了一种新颖的混合检索增强范式，该范式定义了事件语义区域，并通过从该区域中采样出伪样例以提高模型的类比能力。通过在RAMS和WikiEvents上进行充分实验，展示了所提出的检索增强方法的有效性，并对其有效性进行了进一步深入的分析。
                            </font>
                        </p>
                        <br>
                        <p style="text-indent:2em;">
                            <font size="3">即将举办<a href="../Seminar.html">【ACL
                                    2023中稿论文分享会】</a>，如有建议和意见请联系宋传承songchuancheng@iie.ac.an</font>
                        </p>
                    </ul>


                </div>
            </div>
        </div>
    </div>


    <div id="footer" class="container-fluid ">
        <nav class="navbar navbar-default text-center ">
            <div class="navbar-inner navbar-text text-center col-sm-12 column">
                <p class="text-muted credit " style="padding: 0.1%;">
                    ASCII Lab, Institute of Information Engineering, Chinese Academy of Sciences. No.19 Shucun Road,
                    Haidian District, Beijing, China<a
                        href="https://map.baidu.com/poi/%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E9%99%A2%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E7%A0%94%E7%A9%B6%E6%89%80/@12947450.025,4841838.03,19z?uid=dcaaf0f6ea39b2f7badf8f48&info_merge=1&isBizPoi=false&ugc_type=3&ugc_ver=1&device_ratio=1&compat=1&pcevaname=pc4.1&querytype=detailConInfo&da_src=shareurl">(Map)</a>
                    100085
                </p>

            </div>
        </nav>
    </div>


</body>

</html>